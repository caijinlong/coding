Meta VERSION="1" .
Job JOBID="job_201307291428_0011" JOBNAME="NA" USER="guoliqiang" SUBMIT_TIME="1375100211702" JOBCONF="hdfs://localhost:9000/usr/local/hadoop/hadooptmp/mapred/staging/guoliqiang/\.staging/job_201307291428_0011/job\.xml" VIEW_JOB="*" MODIFY_JOB="*" JOB_QUEUE="default" .
Job JOBID="job_201307291428_0011" JOB_PRIORITY="NORMAL" .
Job JOBID="job_201307291428_0011" LAUNCH_TIME="1375100211839" TOTAL_MAPS="3" TOTAL_REDUCES="1" JOB_STATUS="PREP" .
Task TASKID="task_201307291428_0011_r_000002" TASK_TYPE="SETUP" START_TIME="1375100211927" SPLITS="" .
ReduceAttempt TASK_TYPE="SETUP" TASKID="task_201307291428_0011_r_000002" TASK_ATTEMPT_ID="attempt_201307291428_0011_r_000002_0" START_TIME="1375100212025" TRACKER_NAME="tracker_guoliqiang-desktop:localhost/127\.0\.0\.1:33622" HTTP_PORT="50060" .
ReduceAttempt TASK_TYPE="SETUP" TASKID="task_201307291428_0011_r_000002" TASK_ATTEMPT_ID="attempt_201307291428_0011_r_000002_0" TASK_STATUS="SUCCESS" SHUFFLE_FINISHED="1375100213686" SORT_FINISHED="1375100213686" FINISH_TIME="1375100213686" HOSTNAME="/default-rack/guoliqiang-desktop" STATE_STRING="setup" COUNTERS="{(FileSystemCounters)(FileSystemCounters)[(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(54314)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(REDUCE_INPUT_GROUPS)(Reduce input groups)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(REDUCE_SHUFFLE_BYTES)(Reduce shuffle bytes)(0)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(103030784)][(REDUCE_OUTPUT_RECORDS)(Reduce output records)(0)][(SPILLED_RECORDS)(Spilled Records)(0)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(70)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(62324736)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(623046656)][(REDUCE_INPUT_RECORDS)(Reduce input records)(0)]}" .
Task TASKID="task_201307291428_0011_r_000002" TASK_TYPE="SETUP" TASK_STATUS="SUCCESS" FINISH_TIME="1375100213740" COUNTERS="{(FileSystemCounters)(FileSystemCounters)[(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(54314)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(REDUCE_INPUT_GROUPS)(Reduce input groups)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(REDUCE_SHUFFLE_BYTES)(Reduce shuffle bytes)(0)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(103030784)][(REDUCE_OUTPUT_RECORDS)(Reduce output records)(0)][(SPILLED_RECORDS)(Spilled Records)(0)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(70)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(62324736)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(623046656)][(REDUCE_INPUT_RECORDS)(Reduce input records)(0)]}" .
Job JOBID="job_201307291428_0011" JOB_STATUS="RUNNING" .
Task TASKID="task_201307291428_0011_m_000000" TASK_TYPE="MAP" START_TIME="1375100220699" SPLITS="/default-rack/guoliqiang-desktop" .
Task TASKID="task_201307291428_0011_m_000001" TASK_TYPE="MAP" START_TIME="1375100222875" SPLITS="/default-rack/guoliqiang-desktop" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201307291428_0011_m_000000" TASK_ATTEMPT_ID="attempt_201307291428_0011_m_000000_0" START_TIME="1375100220709" TRACKER_NAME="tracker_guoliqiang-desktop:localhost/127\.0\.0\.1:33622" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201307291428_0011_m_000000" TASK_ATTEMPT_ID="attempt_201307291428_0011_m_000000_0" TASK_STATUS="SUCCESS" FINISH_TIME="1375100228416" HOSTNAME="/default-rack/guoliqiang-desktop" STATE_STRING="hdfs://localhost:9000/usr/local/hadoop/hdfs/input/hello\.txt:0+5" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(11)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(123)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(54487)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_OUTPUT_MATERIALIZED_BYTES)(Map output materialized bytes)(25)][(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(2)][(MAP_OUTPUT_BYTES)(Map output bytes)(15)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(158793728)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(480)][(MAP_INPUT_BYTES)(Map input bytes)(11)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(112)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(194265088)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(682766336)][(MAP_OUTPUT_RECORDS)(Map output records)(2)]}" .
Task TASKID="task_201307291428_0011_m_000000" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1375100228617" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(11)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(123)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(54487)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_OUTPUT_MATERIALIZED_BYTES)(Map output materialized bytes)(25)][(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(2)][(MAP_OUTPUT_BYTES)(Map output bytes)(15)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(158793728)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(480)][(MAP_INPUT_BYTES)(Map input bytes)(11)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(112)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(194265088)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(682766336)][(MAP_OUTPUT_RECORDS)(Map output records)(2)]}" .
Task TASKID="task_201307291428_0011_m_000002" TASK_TYPE="MAP" START_TIME="1375100228619" SPLITS="/default-rack/guoliqiang-desktop" .
Task TASKID="task_201307291428_0011_r_000000" TASK_TYPE="REDUCE" START_TIME="1375100228619" SPLITS="" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201307291428_0011_m_000001" TASK_ATTEMPT_ID="attempt_201307291428_0011_m_000001_0" START_TIME="1375100222907" TRACKER_NAME="tracker_guoliqiang-desktop:localhost/127\.0\.0\.1:33622" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201307291428_0011_m_000001" TASK_ATTEMPT_ID="attempt_201307291428_0011_m_000001_0" TASK_STATUS="SUCCESS" FINISH_TIME="1375100229933" HOSTNAME="/default-rack/guoliqiang-desktop" STATE_STRING="hdfs://localhost:9000/usr/local/hadoop/hdfs/input/hello\.txt:5+5" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(6)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(118)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(54468)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_OUTPUT_MATERIALIZED_BYTES)(Map output materialized bytes)(6)][(MAP_INPUT_RECORDS)(Map input records)(0)][(SPILLED_RECORDS)(Spilled Records)(0)][(MAP_OUTPUT_BYTES)(Map output bytes)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(158793728)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(420)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(112)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(191897600)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(626155520)][(MAP_OUTPUT_RECORDS)(Map output records)(0)]}" .
Task TASKID="task_201307291428_0011_m_000001" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1375100230131" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(6)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(118)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(54468)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_OUTPUT_MATERIALIZED_BYTES)(Map output materialized bytes)(6)][(MAP_INPUT_RECORDS)(Map input records)(0)][(SPILLED_RECORDS)(Spilled Records)(0)][(MAP_OUTPUT_BYTES)(Map output bytes)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(158793728)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(420)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(112)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(191897600)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(626155520)][(MAP_OUTPUT_RECORDS)(Map output records)(0)]}" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201307291428_0011_m_000002" TASK_ATTEMPT_ID="attempt_201307291428_0011_m_000002_0" START_TIME="1375100228640" TRACKER_NAME="tracker_guoliqiang-desktop:localhost/127\.0\.0\.1:33622" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201307291428_0011_m_000002" TASK_ATTEMPT_ID="attempt_201307291428_0011_m_000002_0" TASK_STATUS="SUCCESS" FINISH_TIME="1375100236305" HOSTNAME="/default-rack/guoliqiang-desktop" STATE_STRING="hdfs://localhost:9000/usr/local/hadoop/hdfs/input/hello\.txt:10+1" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(1)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(113)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(54468)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_OUTPUT_MATERIALIZED_BYTES)(Map output materialized bytes)(6)][(MAP_INPUT_RECORDS)(Map input records)(0)][(SPILLED_RECORDS)(Spilled Records)(0)][(MAP_OUTPUT_BYTES)(Map output bytes)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(158793728)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(600)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(112)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(198475776)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(610758656)][(MAP_OUTPUT_RECORDS)(Map output records)(0)]}" .
Task TASKID="task_201307291428_0011_m_000002" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1375100236472" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(1)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(113)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(54468)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_OUTPUT_MATERIALIZED_BYTES)(Map output materialized bytes)(6)][(MAP_INPUT_RECORDS)(Map input records)(0)][(SPILLED_RECORDS)(Spilled Records)(0)][(MAP_OUTPUT_BYTES)(Map output bytes)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(158793728)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(600)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(112)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(198475776)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(610758656)][(MAP_OUTPUT_RECORDS)(Map output records)(0)]}" .
ReduceAttempt TASK_TYPE="REDUCE" TASKID="task_201307291428_0011_r_000000" TASK_ATTEMPT_ID="attempt_201307291428_0011_r_000000_0" START_TIME="1375100228648" TRACKER_NAME="tracker_guoliqiang-desktop:localhost/127\.0\.0\.1:33622" HTTP_PORT="50060" .
ReduceAttempt TASK_TYPE="REDUCE" TASKID="task_201307291428_0011_r_000000" TASK_ATTEMPT_ID="attempt_201307291428_0011_r_000000_0" TASK_STATUS="FAILED" FINISH_TIME="1375100240967" HOSTNAME="guoliqiang-desktop" ERROR="java\.io\.IOException: The temporary job-output directory hdfs://localhost:9000/usr/local/hadoop/hdfs/output/_temporary doesn't exist!
	at org\.apache\.hadoop\.mapred\.FileOutputCommitter\.getWorkPath(FileOutputCommitter\.java:250)
	at org\.apache\.hadoop\.mapred\.FileOutputFormat\.getTaskOutputPath(FileOutputFormat\.java:244)
	at org\.apache\.hadoop\.mapred\.TextOutputFormat\.getRecordWriter(TextOutputFormat\.java:116)
	at org\.apache\.hadoop\.mapred\.ReduceTask$OldTrackingRecordWriter\.<init>(ReduceTask\.java:449)
	at org\.apache\.hadoop\.mapred\.ReduceTask\.runOldReducer(ReduceTask\.java:491)
	at org\.apache\.hadoop\.mapred\.ReduceTask\.run(ReduceTask\.java:421)
	at org\.apache\.hadoop\.mapred\.Child$4\.run(Child\.java:255)
	at java\.security\.AccessController\.doPrivileged(Native Method)
	at javax\.security\.auth\.Subject\.doAs(Subject\.java:416)
	at org\.apache\.hadoop\.security\.UserGroupInformation\.doAs(UserGroupInformation\.java:1149)
	at org\.apache\.hadoop\.mapred\.Child\.main(Child\.java:249)
" .
ReduceAttempt TASK_TYPE="REDUCE" TASKID="task_201307291428_0011_r_000000" TASK_ATTEMPT_ID="attempt_201307291428_0011_r_000000_1" START_TIME="1375100241004" TRACKER_NAME="tracker_guoliqiang-desktop:localhost/127\.0\.0\.1:33622" HTTP_PORT="50060" .
ReduceAttempt TASK_TYPE="REDUCE" TASKID="task_201307291428_0011_r_000000" TASK_ATTEMPT_ID="attempt_201307291428_0011_r_000000_1" TASK_STATUS="FAILED" FINISH_TIME="1375100251849" HOSTNAME="guoliqiang-desktop" ERROR="java\.io\.IOException: The temporary job-output directory hdfs://localhost:9000/usr/local/hadoop/hdfs/output/_temporary doesn't exist!
	at org\.apache\.hadoop\.mapred\.FileOutputCommitter\.getWorkPath(FileOutputCommitter\.java:250)
	at org\.apache\.hadoop\.mapred\.FileOutputFormat\.getTaskOutputPath(FileOutputFormat\.java:244)
	at org\.apache\.hadoop\.mapred\.TextOutputFormat\.getRecordWriter(TextOutputFormat\.java:116)
	at org\.apache\.hadoop\.mapred\.ReduceTask$OldTrackingRecordWriter\.<init>(ReduceTask\.java:449)
	at org\.apache\.hadoop\.mapred\.ReduceTask\.runOldReducer(ReduceTask\.java:491)
	at org\.apache\.hadoop\.mapred\.ReduceTask\.run(ReduceTask\.java:421)
	at org\.apache\.hadoop\.mapred\.Child$4\.run(Child\.java:255)
	at java\.security\.AccessController\.doPrivileged(Native Method)
	at javax\.security\.auth\.Subject\.doAs(Subject\.java:416)
	at org\.apache\.hadoop\.security\.UserGroupInformation\.doAs(UserGroupInformation\.java:1149)
	at org\.apache\.hadoop\.mapred\.Child\.main(Child\.java:249)
" .
ReduceAttempt TASK_TYPE="REDUCE" TASKID="task_201307291428_0011_r_000000" TASK_ATTEMPT_ID="attempt_201307291428_0011_r_000000_2" START_TIME="1375100251885" TRACKER_NAME="tracker_guoliqiang-desktop:localhost/127\.0\.0\.1:33622" HTTP_PORT="50060" .
ReduceAttempt TASK_TYPE="REDUCE" TASKID="task_201307291428_0011_r_000000" TASK_ATTEMPT_ID="attempt_201307291428_0011_r_000000_2" TASK_STATUS="FAILED" FINISH_TIME="1375100262692" HOSTNAME="guoliqiang-desktop" ERROR="java\.io\.IOException: The temporary job-output directory hdfs://localhost:9000/usr/local/hadoop/hdfs/output/_temporary doesn't exist!
	at org\.apache\.hadoop\.mapred\.FileOutputCommitter\.getWorkPath(FileOutputCommitter\.java:250)
	at org\.apache\.hadoop\.mapred\.FileOutputFormat\.getTaskOutputPath(FileOutputFormat\.java:244)
	at org\.apache\.hadoop\.mapred\.TextOutputFormat\.getRecordWriter(TextOutputFormat\.java:116)
	at org\.apache\.hadoop\.mapred\.ReduceTask$OldTrackingRecordWriter\.<init>(ReduceTask\.java:449)
	at org\.apache\.hadoop\.mapred\.ReduceTask\.runOldReducer(ReduceTask\.java:491)
	at org\.apache\.hadoop\.mapred\.ReduceTask\.run(ReduceTask\.java:421)
	at org\.apache\.hadoop\.mapred\.Child$4\.run(Child\.java:255)
	at java\.security\.AccessController\.doPrivileged(Native Method)
	at javax\.security\.auth\.Subject\.doAs(Subject\.java:416)
	at org\.apache\.hadoop\.security\.UserGroupInformation\.doAs(UserGroupInformation\.java:1149)
	at org\.apache\.hadoop\.mapred\.Child\.main(Child\.java:249)
" .
ReduceAttempt TASK_TYPE="REDUCE" TASKID="task_201307291428_0011_r_000000" TASK_ATTEMPT_ID="attempt_201307291428_0011_r_000000_3" START_TIME="1375100262758" TRACKER_NAME="tracker_guoliqiang-desktop:localhost/127\.0\.0\.1:33622" HTTP_PORT="50060" .
ReduceAttempt TASK_TYPE="REDUCE" TASKID="task_201307291428_0011_r_000000" TASK_ATTEMPT_ID="attempt_201307291428_0011_r_000000_3" TASK_STATUS="FAILED" FINISH_TIME="1375100273954" HOSTNAME="guoliqiang-desktop" ERROR="java\.io\.IOException: The temporary job-output directory hdfs://localhost:9000/usr/local/hadoop/hdfs/output/_temporary doesn't exist!
	at org\.apache\.hadoop\.mapred\.FileOutputCommitter\.getWorkPath(FileOutputCommitter\.java:250)
	at org\.apache\.hadoop\.mapred\.FileOutputFormat\.getTaskOutputPath(FileOutputFormat\.java:244)
	at org\.apache\.hadoop\.mapred\.TextOutputFormat\.getRecordWriter(TextOutputFormat\.java:116)
	at org\.apache\.hadoop\.mapred\.ReduceTask$OldTrackingRecordWriter\.<init>(ReduceTask\.java:449)
	at org\.apache\.hadoop\.mapred\.ReduceTask\.runOldReducer(ReduceTask\.java:491)
	at org\.apache\.hadoop\.mapred\.ReduceTask\.run(ReduceTask\.java:421)
	at org\.apache\.hadoop\.mapred\.Child$4\.run(Child\.java:255)
	at java\.security\.AccessController\.doPrivileged(Native Method)
	at javax\.security\.auth\.Subject\.doAs(Subject\.java:416)
	at org\.apache\.hadoop\.security\.UserGroupInformation\.doAs(UserGroupInformation\.java:1149)
	at org\.apache\.hadoop\.mapred\.Child\.main(Child\.java:249)
" .
Task TASKID="task_201307291428_0011_r_000000" TASK_TYPE="REDUCE" TASK_STATUS="FAILED" FINISH_TIME="1375100273954" ERROR="java\.io\.IOException: The temporary job-output directory hdfs://localhost:9000/usr/local/hadoop/hdfs/output/_temporary doesn't exist!
	at org\.apache\.hadoop\.mapred\.FileOutputCommitter\.getWorkPath(FileOutputCommitter\.java:250)
	at org\.apache\.hadoop\.mapred\.FileOutputFormat\.getTaskOutputPath(FileOutputFormat\.java:244)
	at org\.apache\.hadoop\.mapred\.TextOutputFormat\.getRecordWriter(TextOutputFormat\.java:116)
	at org\.apache\.hadoop\.mapred\.ReduceTask$OldTrackingRecordWriter\.<init>(ReduceTask\.java:449)
	at org\.apache\.hadoop\.mapred\.ReduceTask\.runOldReducer(ReduceTask\.java:491)
	at org\.apache\.hadoop\.mapred\.ReduceTask\.run(ReduceTask\.java:421)
	at org\.apache\.hadoop\.mapred\.Child$4\.run(Child\.java:255)
	at java\.security\.AccessController\.doPrivileged(Native Method)
	at javax\.security\.auth\.Subject\.doAs(Subject\.java:416)
	at org\.apache\.hadoop\.security\.UserGroupInformation\.doAs(UserGroupInformation\.java:1149)
	at org\.apache\.hadoop\.mapred\.Child\.main(Child\.java:249)
" TASK_ATTEMPT_ID="" .
Task TASKID="task_201307291428_0011_m_000003" TASK_TYPE="CLEANUP" START_TIME="1375100274224" SPLITS="" .
MapAttempt TASK_TYPE="CLEANUP" TASKID="task_201307291428_0011_m_000003" TASK_ATTEMPT_ID="attempt_201307291428_0011_m_000003_0" START_TIME="1375100274227" TRACKER_NAME="tracker_guoliqiang-desktop:localhost/127\.0\.0\.1:33622" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="CLEANUP" TASKID="task_201307291428_0011_m_000003" TASK_ATTEMPT_ID="attempt_201307291428_0011_m_000003_0" TASK_STATUS="SUCCESS" FINISH_TIME="1375100275933" HOSTNAME="/default-rack/guoliqiang-desktop" STATE_STRING="cleanup" COUNTERS="{(FileSystemCounters)(FileSystemCounters)[(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(54398)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(103944192)][(SPILLED_RECORDS)(Spilled Records)(0)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(180)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(62324736)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(693137408)]}" .
Task TASKID="task_201307291428_0011_m_000003" TASK_TYPE="CLEANUP" TASK_STATUS="SUCCESS" FINISH_TIME="1375100276035" COUNTERS="{(FileSystemCounters)(FileSystemCounters)[(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(54398)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(103944192)][(SPILLED_RECORDS)(Spilled Records)(0)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(180)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(62324736)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(693137408)]}" .
Job JOBID="job_201307291428_0011" FINISH_TIME="1375100276035" JOB_STATUS="FAILED" FINISHED_MAPS="3" FINISHED_REDUCES="0" FAIL_REASON="# of failed Reduce Tasks exceeded allowed limit\. FailedCount: 1\. LastFailedTask: task_201307291428_0011_r_000000" .
